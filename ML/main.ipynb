{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from eofs.xarray import Eof\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data into an xarray dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = xr.open_dataset('/home/disk/eos12/wycheng/data/US/dataset.nc',chunks={'Time':5848, 'lev':'auto', 'lat':'auto', 'lon':'auto'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign a new variable \"isT\" based on whether there is lightning stroke observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.assign(isT=lambda dataset: 1.0*(dataset.F>0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a sub-domain centering around west coast region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.isel(lat=slice(10,20), lon=slice(15,25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use EOF (PCA) to reconstruct the 1-D data (profiles of temperature and moisture profiles) and 2-D data (images of geopotential height) into new features to feed into the ML model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_stacked = dataset['t'].stack(time=('Time','lat','lon')).transpose(\"time\", \"lev\")\n",
    "q_stacked = dataset['q'].stack(time=('Time','lat','lon')).transpose(\"time\", \"lev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "t1d_solver = Eof(t_stacked,center='True')\n",
    "q1d_solver = Eof(q_stacked,center='True')\n",
    "print(\"%s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_pcs = t1d_solver.projectField(t_stacked, eofscaling=1, neofs=10)\n",
    "q_pcs = q1d_solver.projectField(q_stacked, eofscaling=1, neofs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_pcs = t_pcs.unstack().transpose(\"Time\", \"mode\", \"lat\", \"lon\")\n",
    "q_pcs = q_pcs.unstack().transpose(\"Time\", \"mode\", \"lat\", \"lon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imode in range(10):\n",
    "    exec( 'dataset = dataset.assign(tpc'+str(imode)+'=t_pcs[:,imode,:,:])' )\n",
    "    exec( 'dataset = dataset.assign(qpc'+str(imode)+'=q_pcs[:,imode,:,:])' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1d_ve = t1d_solver.varianceFraction(neigs=10)\n",
    "q1d_ve = q1d_solver.varianceFraction(neigs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(1,10,10),t1d_ve,'b-',label='t');\n",
    "plt.plot(np.linspace(1,10,10),np.cumsum(t1d_ve),'b--')\n",
    "plt.plot(np.linspace(1,10,10),q1d_ve,'g-',label='q');\n",
    "plt.plot(np.linspace(1,10,10),np.cumsum(q1d_ve),'g--')\n",
    "plt.legend()\n",
    "plt.xlabel('PC #')\n",
    "plt.ylabel('Fraction of variance explained')\n",
    "plt.xlim([1,10])\n",
    "plt.ylim([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1d_eofs = t1d_solver.eofs(eofscaling=2, neofs=10)\n",
    "q1d_eofs = q1d_solver.eofs(eofscaling=2, neofs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n",
    "ax1.plot(t1d_eofs[0,:],np.linspace(1000,100,10),'b-',label='EOF1')\n",
    "ax1.plot(t1d_eofs[1,:],np.linspace(1000,100,10),'b--',label='EOF2')\n",
    "ax1.plot(t1d_eofs[2,:],np.linspace(1000,100,10),'b:',label='EOF3')\n",
    "\n",
    "ax2.plot(q1d_eofs[0,:],np.linspace(1000,100,10),'g-',label='EOF1')\n",
    "ax2.plot(q1d_eofs[1,:],np.linspace(1000,100,10),'g--',label='EOF2')\n",
    "ax2.plot(q1d_eofs[2,:],np.linspace(1000,100,10),'g:',label='EOF3')\n",
    "\n",
    "ax1.set_ylabel('pressure (hPa)')\n",
    "ax1.set_xlabel('T\\' (K)')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.set_xlabel('q\\' (kg/kg)')\n",
    "ax2.legend()\n",
    "\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ilev in range(10):\n",
    "    exec( 'dataset = dataset.assign(t'+str(ilev)+'=dataset.t[:,ilev,:,:])' )\n",
    "    exec( 'dataset = dataset.assign(q'+str(ilev)+'=dataset.q[:,ilev,:,:])' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dataset.where( (dataset.island == 1) ).to_dataframe().dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchy - 1: Predicting power for CAPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using all levels of T and q directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name  = ['t0','t1','t2','t3','t4','t5','t6','t7','t8','t9','q0','q1','q2','q3','q4','q5','q6','q7','q8','q9']\n",
    "output_name   = ['cape']\n",
    "X = dataframe[feature_name]\n",
    "y = dataframe[output_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfreg = RandomForestRegressor(n_estimators=4,\n",
    "                              max_depth=4,\n",
    "                              random_state=0,\n",
    "                              n_jobs=4,\n",
    "                              verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "rfreg.fit(X_train[feature_name], y_train[output_name].values.ravel())\n",
    "print(\"%s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_rfreg = rfreg.predict(X_test[feature_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_truth = y_test[output_name].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(y_predict_rfreg,y_predict_truth)\n",
    "ax.set_title('R2: ' + str(r2_score(y_predict_rfreg,y_predict_truth)))\n",
    "ax.set_xlabel('CAPE (RF regressor)')\n",
    "ax.set_ylabel('CAPE (ground truth)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, test_scores, fit_times, _ = \\\n",
    "        learning_curve(rfreg, X, y, cv=4, n_jobs=4,\n",
    "                       train_sizes=np.linspace(0.1,1.0,4),\n",
    "                       return_times=True,verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "fit_times_mean = np.mean(fit_times, axis=1)\n",
    "fit_times_std = np.std(fit_times, axis=1)\n",
    "\n",
    "axes.grid()\n",
    "axes.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                      train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                      color=\"r\")\n",
    "axes.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                      test_scores_mean + test_scores_std, alpha=0.1,\n",
    "                      color=\"g\")\n",
    "axes.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "              label=\"Training score\")\n",
    "axes.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "              label=\"Cross-validation score\")\n",
    "axes.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using EOFs of T, q profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_name  = ['tpc0','tpc1','tpc2','tpc3','tpc4','tpc5','tpc6','tpc7','tpc8','tpc9','qpc0','qpc1','qpc2','qpc3','qpc4','qpc5','qpc6','qpc7','qpc8','qpc9']\n",
    "feature_name  = ['tpc0','tpc1','tpc2','tpc3','tpc4','qpc0','qpc1','qpc2','qpc3','qpc4']\n",
    "#feature_name  = ['tpc0','tpc1','tpc2','qpc0','qpc1','qpc2']\n",
    "#feature_name  = ['tpc0','tpc1','qpc0','qpc1']\n",
    "#feature_name  = ['tpc0','qpc0']\n",
    "output_name   = ['cape']\n",
    "X = dataframe[feature_name]\n",
    "y = dataframe[output_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfreg = RandomForestRegressor(n_estimators=4,\n",
    "                              max_depth=4,\n",
    "                              random_state=0,\n",
    "                              n_jobs=4,\n",
    "                              verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "rfreg.fit(X_train[feature_name], y_train[output_name].values.ravel())\n",
    "print(\"%s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_rfreg = rfreg.predict(X_test[feature_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_truth = y_test[output_name].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(y_predict_rfreg,y_predict_truth)\n",
    "ax.set_title('R2: ' + str(r2_score(y_predict_rfreg,y_predict_truth)))\n",
    "ax.set_xlabel('CAPE (RF regressor)')\n",
    "ax.set_ylabel('CAPE (ground truth)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, test_scores, fit_times, _ = \\\n",
    "        learning_curve(rfreg, X, y, cv=4, n_jobs=4,\n",
    "                       train_sizes=np.linspace(0.1,1.0,4),\n",
    "                       return_times=True,verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "fit_times_mean = np.mean(fit_times, axis=1)\n",
    "fit_times_std = np.std(fit_times, axis=1)\n",
    "\n",
    "axes.grid()\n",
    "axes.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                      train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                      color=\"r\")\n",
    "axes.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                      test_scores_mean + test_scores_std, alpha=0.1,\n",
    "                      color=\"g\")\n",
    "axes.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "              label=\"Training score\")\n",
    "axes.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "              label=\"Cross-validation score\")\n",
    "axes.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchy - 2: Predicting power for isT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import accuracy_score, precision_score, average_precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.metrics import plot_roc_curve, plot_precision_recall_curve\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve\n",
    "from sklearn.metrics import auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_models       = 6\n",
    "feature_name0  = ['pcp','cape']\n",
    "feature_name1  = ['pcp','cape']\n",
    "feature_name2  = ['pcp','t0','t1','t2','t3','t4','t5','t6','t7','t8','t9','q0','q1','q2','q3','q4','q5','q6','q7','q8','q9']\n",
    "feature_name3  = ['pcp','tpc0','tpc1','qpc0','qpc1']\n",
    "feature_name4  = ['pcp','tpc0','tpc1','tpc2','qpc0','qpc1','qpc2']\n",
    "feature_name5  = ['pcp','cape','tpc0','tpc1','tpc2','qpc0','qpc1','qpc2']\n",
    "output_name    = ['isT']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataframe.drop(output_name,axis=1)\n",
    "y = dataframe[output_name] \n",
    "                   \n",
    "X_train_raw, X_test, y_train_raw, y_test = train_test_split(X, y, test_size=0.33, random_state=0)\n",
    "X_train, y_train = undersample.fit_resample(X_train_raw, y_train_raw)\n",
    "\n",
    "y_predict_truth = y_test[output_name].values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, confusion_matrix\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class R14:\n",
    "    \n",
    "    def fit(CAPE,pcp,y):\n",
    "\n",
    "        thrs = sp.optimize.fminbound(lambda x: -f1_score(y, ((CAPE*pcp > x) * 1.0).astype(int)), 0, 4000)\n",
    "        fval = f1_score(y, ((CAPE*pcp >= thrs) * 1.0).astype(int))\n",
    "        \n",
    "        return thrs, fval\n",
    "    \n",
    "    def predict(CAPE,pcp,thrs):\n",
    "        \n",
    "        y_predict = ((CAPE*pcp >= thrs) * 1.0).astype(int)\n",
    "        y_predict_proba = CAPE*pcp\n",
    "        \n",
    "        return y_predict, y_predict_proba/np.max(y_predict_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[r14_thrs,fval] = R14.fit(X_train['cape'],X_train['pcp'],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_r14, y_score0 = R14.predict(X_test['cape'],X_test['pcp'],r14_thrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUROCC0 = roc_auc_score(y_predict_truth, y_score0)\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_predict_truth, y_score0)\n",
    "AUPRC0  = auc(recall, precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imodel in np.arange(1,n_models,1):\n",
    "    \n",
    "    exec( 'rfclf'+str(imodel)+' = RandomForestClassifier(n_estimators=10, '\\\n",
    "                               'max_depth=4,'\\\n",
    "                               'min_samples_split=10, '\\\n",
    "                               'random_state=0)' )\n",
    "    \n",
    "    exec( 'rfclf'+str(imodel)+'.fit(X_train[feature_name'+str(imodel)+'], y_train[output_name].values.ravel())' )\n",
    "    \n",
    "    exec( 'y_predict_rfclf'+str(imodel)+' = rfclf'+str(imodel)+'.predict(X_test[feature_name'+str(imodel)+'])' )\n",
    "    \n",
    "    exec( 'y_score'+str(imodel)+' = rfclf'+str(imodel)+'.predict_proba(X_test[feature_name'+str(imodel)+'])[:,1]' )\n",
    "    exec( 'precision, recall, thresholds = precision_recall_curve(y_predict_truth, y_score'+str(imodel)+')' )\n",
    "    \n",
    "    exec( 'AUROCC'+str(imodel)+' = roc_auc_score(y_predict_truth, y_score'+str(imodel)+')' )\n",
    "    exec( 'AUPRC'+str(imodel)+' = auc(recall, precision)' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors  = ['k','b','orange','g','r','purple']\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for imodel in np.arange(0,n_models,1):\n",
    "    exec( 'fpr, tpr, threshold = roc_curve(y_predict_truth, y_score'+str(imodel)+')' )\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    ax.plot(fpr, tpr, c=colors[imodel], label = 'Model '+str(imodel)+' (AUC = %0.2f)'% roc_auc)\n",
    "    \n",
    "plt.xlabel('False Alarm Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(fontsize=12,loc='best')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "for imodel in np.arange(0,n_models,1):\n",
    "    exec( 'precision, recall, thresholds = precision_recall_curve(y_predict_truth, y_score'+str(imodel)+')' )\n",
    "    pr_auc = auc(recall, precision)\n",
    "    ax.plot(precision, recall, c=colors[imodel], label = 'Model '+str(imodel)+' (AUC = %0.2f)'% pr_auc)\n",
    "    \n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(fontsize=12,loc='best')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = ['.','v','s','p','*','x','d']\n",
    "fig, ax = plt.subplots()\n",
    "for imodel in np.arange(0,n_models,1):\n",
    "    exec( 'ax.scatter(AUPRC'+str(imodel)+',AUROCC'+str(imodel)+', c=colors[imodel], marker=\\''+markers[imodel]+'\\',label=\\'Model '+str(imodel)+'\\')' )\n",
    "\n",
    "ax.set_title('Model skill')\n",
    "ax.set_xlabel('Area under PR curve')\n",
    "ax.set_ylabel('Area under ROC curve')\n",
    "#ax.set_xlim([0.40,0.55])\n",
    "#ax.set_ylim([0.75,0.95])\n",
    "ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the performance for dry thunderstorms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp_thrs = 0.1\n",
    "Xdt_test = X_test.where(X_test.pcp<pcp_thrs).dropna()\n",
    "ydt_predict_truth = y_test[output_name].where(X_test.pcp<pcp_thrs).dropna().values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dry thunderstorm fraction (i.e., the ratio between dry thunderstorms and all thunderstorms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test.where(y_test.isT>0).where(X_test.pcp<0.1).count()/y_test.where(y_test.isT>0).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ydt_predict_r14, ydt_score0 = R14.predict(Xdt_test['cape'],Xdt_test['pcp'],r14_thrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUROCC0 = roc_auc_score(y_predict_truth, y_score0)\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(ydt_predict_truth, ydt_score0)\n",
    "AUPRC0  = auc(recall, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imodel in np.arange(1,n_models,1):\n",
    "    \n",
    "    exec( 'ydt_predict_rfclf'+str(imodel)+' = rfclf'+str(imodel)+'.predict(Xdt_test[feature_name'+str(imodel)+'])' )\n",
    "    \n",
    "    exec( 'ydt_score'+str(imodel)+' = rfclf'+str(imodel)+'.predict_proba(Xdt_test[feature_name'+str(imodel)+'])[:,1]' )\n",
    "    exec( 'precision, recall, thresholds = precision_recall_curve(ydt_predict_truth, ydt_score'+str(imodel)+')' )\n",
    "    \n",
    "    exec( 'AUROCC'+str(imodel)+' = roc_auc_score(ydt_predict_truth, ydt_score'+str(imodel)+')' )\n",
    "    exec( 'AUPRC'+str(imodel)+' = auc(recall, precision)' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors  = ['k','b','orange','g','r','purple']\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for imodel in np.arange(0,n_models,1):\n",
    "    exec( 'fpr, tpr, threshold = roc_curve(ydt_predict_truth, ydt_score'+str(imodel)+')' )\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    ax.plot(fpr, tpr, c=colors[imodel], label = 'Model '+str(imodel)+' (AUC = %0.2f)'% roc_auc)\n",
    "    \n",
    "plt.xlabel('False Alarm Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(fontsize=12,loc='best')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "for imodel in np.arange(0,n_models,1):\n",
    "    exec( 'precision, recall, thresholds = precision_recall_curve(ydt_predict_truth, ydt_score'+str(imodel)+')' )\n",
    "    pr_auc = auc(recall, precision)\n",
    "    ax.plot(precision, recall, c=colors[imodel], label = 'Model '+str(imodel)+' (AUC = %0.2f)'% pr_auc)\n",
    "    \n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(fontsize=12,loc='best')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = ['.','v','s','p','*','x','d']\n",
    "fig, ax = plt.subplots()\n",
    "for imodel in np.arange(0,n_models,1):\n",
    "    exec( 'ax.scatter(AUPRC'+str(imodel)+',AUROCC'+str(imodel)+', c=colors[imodel], marker=\\''+markers[imodel]+'\\',label=\\'Model '+str(imodel)+'\\')' )\n",
    "\n",
    "ax.set_title('Model skill')\n",
    "ax.set_xlabel('Area under PR curve')\n",
    "ax.set_ylabel('Area under ROC curve')\n",
    "#ax.set_xlim([0.40,0.55])\n",
    "#ax.set_ylim([0.75,0.95])\n",
    "ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
