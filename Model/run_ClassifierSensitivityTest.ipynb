{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-calendar",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sixth-carol",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import dask\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from eofs.xarray import Eof\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "least-costs",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informal-xerox",
   "metadata": {},
   "outputs": [],
   "source": [
    "island_dataset = xr.open_dataset('/home/disk/eos12/wycheng/data/US/island/island_1deg_US.nc',\n",
    "                                  chunks={'lat':'auto', 'lon':'auto'}).sel(lat=slice(30,40), lon=slice(-120,-110))\n",
    "display(island_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-colors",
   "metadata": {},
   "outputs": [],
   "source": [
    "WWLLN_dataset = xr.open_mfdataset('/home/disk/eos12/wycheng/data/US/WWLLN/WWLLN_*_F_cg_1deg3hr_US.nc',\n",
    "                                  parallel=True,\n",
    "                                  chunks={'Time':'auto', 'lat':'auto', 'lon':'auto'}).sel(lat=slice(30,40), lon=slice(-120,-110))\n",
    "WWLLN_dataset['F'] = (1/((111.19492664455873)**2)) * (365.25*8) * WWLLN_dataset['F']\n",
    "display(WWLLN_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessible-alert",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRMM_dataset = xr.open_mfdataset('/home/disk/eos12/wycheng/data/US/TRMM/TRMM_*_pcp_cg_1deg3hr_US.nc',\n",
    "                                  parallel=True,\n",
    "                                  chunks={'Time':'auto', 'lat':'auto', 'lon':'auto'}).sel(lat=slice(30,40), lon=slice(-120,-110))\n",
    "display(TRMM_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recorded-outside",
   "metadata": {},
   "outputs": [],
   "source": [
    "ERA5_cape_dataset = xr.open_mfdataset('/home/disk/eos12/wycheng/data/US/ERA5/ERA5_cape_*.nc',\n",
    "                                     parallel=True,\n",
    "                                     chunks={'time':'auto', 'latitude':'auto', 'longitude':'auto'}).sel(latitude=slice(40,30), longitude=slice(-120,-110)).compute()\n",
    "\n",
    "ERA5_cape_dataset = ERA5_cape_dataset.rename({'time':'Time', 'latitude':'lat', 'longitude':'lon'})\n",
    "\n",
    "ERA5_cape_dataset = ERA5_cape_dataset.resample(Time=\"3h\").mean()\n",
    "\n",
    "lono = xr.DataArray(np.linspace(-119.5,-110.5,10), dims='lon')\n",
    "lato = xr.DataArray(np.linspace(30.5,39.5,10), dims='lat')\n",
    "\n",
    "with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
    "    ERA5_cape_dataset = ERA5_cape_dataset.interp(lon=lono,lat=lato,method='linear')\n",
    "\n",
    "display(ERA5_cape_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sweet-indianapolis",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = xr.merge([island_dataset, WWLLN_dataset, TRMM_dataset, ERA5_cape_dataset]).sel(Time=slice(\"2010-01-01\", \"2019-12-31\"))\n",
    "display(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-durham",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.to_netcdf(path='/home/disk/eos12/wycheng/data/US/dataset/dataset_test.nc', mode='w')\n",
    "#dataset = xr.open_dataset('/home/disk/eos12/wycheng/data/US/dataset/dataset_test.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weird-washer",
   "metadata": {},
   "source": [
    "# Set country borders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-savings",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regionmask\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-swift",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_SHAPEFILE = '/home/disk/eos10/wycheng/LightningMachineLearning/data/WorldCountriesBoundaries/99bfd9e7-bb42-4728-87b5-07f8c8ac631c2020328-1-1vef4ev.lu5nk.shp'\n",
    "countries = gpd.read_file(PATH_TO_SHAPEFILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-whale",
   "metadata": {},
   "source": [
    "# ML Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "critical-drawing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, average_precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.metrics import plot_roc_curve, plot_precision_recall_curve\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve\n",
    "from sklearn.metrics import auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-dragon",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.assign(TO=lambda dataset: 1.0*(dataset.F>0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comfortable-kennedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dataset.where( (dataset.island == 1) ).to_dataframe().dropna(axis=0)\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-tournament",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name   = ['pcp','cape']\n",
    "output_name    = ['TO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjustable-hands",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataframe.drop(output_name,axis=1)\n",
    "y = dataframe[output_name] \n",
    "\n",
    "undersample = RandomUnderSampler(sampling_strategy=0.33)\n",
    "                   \n",
    "X_train_raw, X_test, y_train_raw, y_test = train_test_split(X, y, test_size=0.33, random_state=0)\n",
    "X_train, y_train = undersample.fit_resample(X_train_raw, y_train_raw)\n",
    "\n",
    "y_predict_truth = y_test[output_name].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wireless-device",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_models = 5\n",
    "AUCROC = np.zeros((n_models))\n",
    "AUCPRC = np.zeros((n_models))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earned-rings",
   "metadata": {},
   "source": [
    "## R14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-temple",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, confusion_matrix\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "together-knitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "class R14:\n",
    "    \n",
    "    def fit(CAPE,pcp,y):\n",
    "\n",
    "        thrs = sp.optimize.fminbound(lambda x: -f1_score(y, ((CAPE*pcp > x) * 1.0).astype(int)), 0, 4000)\n",
    "        fval = f1_score(y, ((CAPE*pcp >= thrs) * 1.0).astype(int))\n",
    "        \n",
    "        return thrs, fval\n",
    "    \n",
    "    def predict(CAPE,pcp,thrs):\n",
    "        \n",
    "        y_predict = ((CAPE*pcp >= thrs) * 1.0).astype(int)\n",
    "        y_predict_proba = CAPE*pcp\n",
    "        \n",
    "        return y_predict, y_predict_proba/np.max(y_predict_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-consciousness",
   "metadata": {},
   "outputs": [],
   "source": [
    "[r14_thrs,fval] = R14.fit(X_train['cape'],X_train['pcp'],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "systematic-field",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_r14, y_score_r14 = R14.predict(X_test['cape'],X_test['pcp'],r14_thrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documentary-sight",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_predict_truth, y_score_r14)\n",
    "AUCROC[0] = roc_auc_score(y_predict_truth, y_score_r14)\n",
    "AUCPRC[0] = auc(recall, precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-teddy",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perceived-right",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biological-secret",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrclf = LogisticRegression(random_state=0).fit(X_train[feature_name], y_train[output_name].values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flying-aspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_lrclf = lrclf.predict(X_test[feature_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-elder",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score_lrclf = lrclf.predict_proba(X_test[feature_name])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-nepal",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_predict_truth, y_score_lrclf)\n",
    "AUCROC[1]   = roc_auc_score(y_predict_truth, y_score_lrclf)\n",
    "AUCPRC[1]   = auc(recall, precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smoking-payroll",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-maintenance",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-student",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtclf = DecisionTreeClassifier(max_depth=5)\n",
    "\n",
    "dtclf.fit(X_train[feature_name], y_train[output_name].values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-collective",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_dtclf = dtclf.predict(X_test[feature_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confident-benchmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score_dtclf = dtclf.predict_proba(X_test[feature_name])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deluxe-milwaukee",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_predict_truth, y_score_dtclf)\n",
    "AUCROC[2]   = roc_auc_score(y_predict_truth, y_score_dtclf)\n",
    "AUCPRC[2]   = auc(recall, precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "through-quantum",
   "metadata": {},
   "source": [
    "## RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-enforcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thorough-rapid",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfclf = RandomForestClassifier(n_estimators=10, \n",
    "                               max_depth=4,\n",
    "                               min_samples_split=10,\n",
    "                               random_state=0)\n",
    "    \n",
    "rfclf.fit(X_train[feature_name], y_train[output_name].values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infinite-shade",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_rfclf = rfclf.predict(X_test[feature_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiscal-restriction",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score_rfclf = rfclf.predict_proba(X_test[feature_name])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "introductory-surprise",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_predict_truth, y_score_rfclf)\n",
    "AUCROC[3]   = roc_auc_score(y_predict_truth, y_score_rfclf)\n",
    "AUCPRC[3]   = auc(recall, precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liked-steam",
   "metadata": {},
   "source": [
    "## Neural Network Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broad-knight",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improved-islam",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpclf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                       hidden_layer_sizes=(5, 2), random_state=1)\n",
    "\n",
    "mlpclf.fit(X_train[feature_name], y_train[output_name].values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-gabriel",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_mlpclf = mlpclf.predict(X_test[feature_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-roman",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score_mlpclf = mlpclf.predict_proba(X_test[feature_name])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-illustration",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_predict_truth, y_score_mlpclf)\n",
    "AUCROC[4]   = roc_auc_score(y_predict_truth, y_score_mlpclf)\n",
    "AUCPRC[4]   = auc(recall, precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "starting-contest",
   "metadata": {},
   "source": [
    "## Evaluating Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-inspector",
   "metadata": {},
   "outputs": [],
   "source": [
    "models  = ['r14','lrclf','dtclf','rfclf','mlpclf']\n",
    "model_names = ['R14','LR','DT','RF','NN']\n",
    "colors  = ['k','b','orange','g','r','purple']\n",
    "markers = ['.','v','s','p','*','x','d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-cholesterol",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "for imodel in np.arange(0,n_models,1):\n",
    "    exec( 'fpr, tpr, threshold = roc_curve(y_predict_truth, y_score_'+models[imodel]+')' )\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    ax.plot(fpr, tpr, c=colors[imodel], label = model_names[imodel]+' (AUC = %0.2f)'% roc_auc)\n",
    "    \n",
    "plt.xlabel('False Alarm Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(fontsize=12,loc='best')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlike-tolerance",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "for imodel in np.arange(0,n_models,1):\n",
    "    exec( 'precision, recall, thresholds = precision_recall_curve(y_predict_truth, y_score_'+models[imodel]+')' )\n",
    "    pr_auc = auc(recall, precision)\n",
    "    ax.plot(precision, recall, c=colors[imodel], label = model_names[imodel]+' (AUC = %0.2f)'% pr_auc)\n",
    "    \n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(fontsize=12,loc='best')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleased-freedom",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "for imodel in np.arange(0,n_models,1):\n",
    "    ax.scatter(AUCPRC[imodel],AUCROC[imodel], c=colors[imodel], marker=markers[imodel],label=model_names[imodel])\n",
    "\n",
    "ax.set_title('Model skill')\n",
    "ax.set_xlabel('Area under PR curve')\n",
    "ax.set_ylabel('Area under ROC curve')\n",
    "#ax.set_xlim([0.25,0.5])\n",
    "#ax.set_ylim([0.7,0.95])\n",
    "ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "headed-stuff",
   "metadata": {},
   "source": [
    "# Examine the performance for dry thunderstorms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-trader",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp_thrs = 0.01\n",
    "Xdt_test = X_test.where(X_test['pcp']<pcp_thrs).dropna()\n",
    "ydt_predict_truth = y_test[output_name].where(X_test.pcp<pcp_thrs).dropna().values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forced-testimony",
   "metadata": {},
   "source": [
    "the ratio between dry thunderstorms and total thunderstorms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polyphonic-copper",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test.where(y_test['TO']>0).where(X_test.pcp<pcp_thrs).count()/y_test.where(y_test['TO']>0).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-chair",
   "metadata": {},
   "outputs": [],
   "source": [
    "ydt_predict_r14, ydt_score0 = R14.predict(Xdt_test['cape'],Xdt_test['pcp'],r14_thrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-still",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUCROC = np.zeros((n_models))\n",
    "AUCPRC = np.zeros((n_models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-scotland",
   "metadata": {},
   "outputs": [],
   "source": [
    "ydt_predict_r14,    ydt_score_r14     = R14.predict(Xdt_test['cape'],Xdt_test['pcp'],r14_thrs)\n",
    "\n",
    "ydt_score_lrclf   = lrclf.predict_proba(Xdt_test[feature_name])[:,1]\n",
    "ydt_score_dtclf   = dtclf.predict_proba(Xdt_test[feature_name])[:,1]\n",
    "ydt_score_rfclf   = rfclf.predict_proba(Xdt_test[feature_name])[:,1]\n",
    "ydt_score_mlpclf  = mlpclf.predict_proba(Xdt_test[feature_name])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threatened-cigarette",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(ydt_predict_truth, ydt_score_r14)\n",
    "AUCROC[0] = roc_auc_score(ydt_predict_truth, ydt_score_r14)\n",
    "AUCPRC[0] = auc(recall, precision)\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(ydt_predict_truth, ydt_score_lrclf)\n",
    "AUCROC[1] = roc_auc_score(ydt_predict_truth, ydt_score_lrclf)\n",
    "AUCPRC[1] = auc(recall, precision)\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(ydt_predict_truth, ydt_score_dtclf)\n",
    "AUCROC[2] = roc_auc_score(ydt_predict_truth, ydt_score_dtclf)\n",
    "AUCPRC[2] = auc(recall, precision)\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(ydt_predict_truth, ydt_score_rfclf)\n",
    "AUCROC[3] = roc_auc_score(ydt_predict_truth, ydt_score_rfclf)\n",
    "AUCPRC[3] = auc(recall, precision)\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(ydt_predict_truth, ydt_score_mlpclf)\n",
    "AUCROC[4] = roc_auc_score(ydt_predict_truth, ydt_score_mlpclf)\n",
    "AUCPRC[4] = auc(recall, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-momentum",
   "metadata": {},
   "outputs": [],
   "source": [
    "models  = ['r14','lrclf','dtclf','rfclf','mlpclf']\n",
    "model_names = ['R14','LR','DT','RF','NN']\n",
    "colors  = ['k','b','orange','g','r','purple']\n",
    "markers = ['.','v','s','p','*','x','d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-cruise",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "for imodel in np.arange(0,n_models,1):\n",
    "    exec( 'fpr, tpr, threshold = roc_curve(ydt_predict_truth, ydt_score_'+models[imodel]+')' )\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    ax.plot(fpr, tpr, c=colors[imodel], label = model_names[imodel]+' (AUC = %0.2f)'% roc_auc)\n",
    "    \n",
    "plt.xlabel('False Alarm Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(fontsize=12,loc='best')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescribed-flight",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "for imodel in np.arange(0,n_models,1):\n",
    "    exec( 'precision, recall, thresholds = precision_recall_curve(ydt_predict_truth, ydt_score_'+models[imodel]+')' )\n",
    "    pr_auc = auc(recall, precision)\n",
    "    ax.plot(precision, recall, c=colors[imodel], label = model_names[imodel]+' (AUC = %0.2f)'% pr_auc)\n",
    "    \n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(fontsize=12,loc='best')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neutral-survey",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "for imodel in np.arange(0,n_models,1):\n",
    "    ax.scatter(AUCPRC[imodel],AUCROC[imodel], c=colors[imodel], marker=markers[imodel],label=model_names[imodel])\n",
    "\n",
    "ax.set_title('Model skill')\n",
    "ax.set_xlabel('Area under PR curve')\n",
    "ax.set_ylabel('Area under ROC curve')\n",
    "#ax.set_xlim([0.25,0.5])\n",
    "#ax.set_ylim([0.7,0.95])\n",
    "ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-consultancy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balanced-compound",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forty-uganda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-destiny",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-summer",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = xr.open_dataset('/home/disk/eos12/wycheng/dataset_CAL.nc')\n",
    "display(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adult-flash",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
